{
  "master": {
    "tasks": [
      {
        "id": "9",
        "title": "Create CoVe skill directory structure and SKILL.md entry point",
        "description": "Set up the CoVe skill directory at `.claude/skills/cove/` (via `.github/templates/claude/skills/cove/`) and create the SKILL.md entry point file with proper YAML frontmatter and skill overview.",
        "details": "Create the skill directory structure following existing patterns in `.github/templates/claude/skills/`.\n\n**File: `.github/templates/claude/skills/cove/SKILL.md`**\n\nYAML frontmatter structure:\n```yaml\n---\nname: cove\ndescription: Apply Chain-of-Verification (CoVe) prompting to improve response accuracy through self-verification. Use for complex questions requiring fact-checking, technical accuracy, or multi-step reasoning.\n---\n```\n\nContent requirements:\n1. Brief explanation of CoVe purpose (1-2 paragraphs)\n2. When to use this skill (bullet list):\n   - Complex factual questions\n   - Technical specifications and API behavior\n   - Multi-step reasoning chains\n   - Code generation requiring accuracy verification\n3. Reference to `cove-process.md` for the detailed workflow\n4. Note about invocation via `/cove` command\n\nFollow the concise pattern from `development-guidelines/SKILL.md` - keep entry point brief, details go in process file.",
        "testStrategy": "1. Verify directory `.github/templates/claude/skills/cove/` exists\n2. Verify `SKILL.md` contains valid YAML frontmatter with `name: cove`\n3. Verify description mentions accuracy, verification, and complex questions\n4. Verify file references `cove-process.md`\n5. Check file follows existing skill format conventions (compare with `analysis-process/SKILL.md`)",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create CoVe skill directory structure",
            "description": "Create the `.github/templates/claude/skills/cove/` directory to house the CoVe skill files, following the existing skill directory pattern in the templates folder.",
            "dependencies": [],
            "details": "Create the directory structure at `.github/templates/claude/skills/cove/`. This follows the existing pattern where each skill has its own subdirectory under the skills folder (e.g., `development-guidelines/`, `analysis-process/`, `testing-process/`). The directory should be created empty initially, ready to receive the SKILL.md and cove-process.md files in subsequent steps. Verify the directory exists and is at the correct location relative to other skill directories.\n<info added on 2026-02-01T15:06:19.899Z>\nI'll analyze the codebase to understand the project structure and then provide the appropriate update for subtask 9.1.Based on my analysis of the codebase structure and the design documents, here's the new information that should be appended to subtask 9.1:\n\nReference the complete CoVe design specification at docs/wip/cove/design.md for architectural details including the 4-step verification process flow, output format template structure, and verification question categories. Implementation details and file structure conventions are documented in docs/wip/cove/implementation.md which covers the SKILL.md frontmatter requirements, cove-process.md workflow sections, and slash command argument handling patterns matching existing skills like analysis-process.\n</info added on 2026-02-01T15:06:19.899Z>",
            "status": "done",
            "testStrategy": "Verify directory `.github/templates/claude/skills/cove/` exists using `ls -la .github/templates/claude/skills/` and confirm it appears alongside existing skill directories (analysis-process, development-guidelines, etc.)",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:17:13.535Z"
          },
          {
            "id": 2,
            "title": "Create SKILL.md with YAML frontmatter",
            "description": "Create the SKILL.md entry point file with proper YAML frontmatter containing the skill name and description fields as specified in the task details.",
            "dependencies": [
              1
            ],
            "details": "Create `.github/templates/claude/skills/cove/SKILL.md` with YAML frontmatter structure:\n```yaml\n---\nname: cove\ndescription: Apply Chain-of-Verification (CoVe) prompting to improve response accuracy through self-verification. Use for complex questions requiring fact-checking, technical accuracy, or multi-step reasoning.\n---\n```\nThe frontmatter format must match the existing pattern in `development-guidelines/SKILL.md` - using exactly `name:` and `description:` fields. The description should mention accuracy, verification, and complex questions as per the task specification.",
            "status": "done",
            "testStrategy": "Parse YAML frontmatter to verify: 1) `name` field equals 'cove', 2) `description` contains 'verification', 'accuracy', and 'complex' keywords, 3) YAML is valid and follows existing skill frontmatter patterns",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:17:13.540Z"
          },
          {
            "id": 3,
            "title": "Add SKILL.md content body with purpose and usage guidance",
            "description": "Add the content body to SKILL.md including CoVe purpose explanation, when-to-use bullet list, reference to cove-process.md, and invocation note.",
            "dependencies": [
              2
            ],
            "details": "Add content after the YAML frontmatter following the concise pattern from `development-guidelines/SKILL.md`. Required content:\n\n1. **Brief CoVe explanation** (1-2 paragraphs): Explain that CoVe is a verification technique that improves response accuracy through systematic self-verification\n\n2. **When to use this skill** (bullet list):\n   - Complex factual questions\n   - Technical specifications and API behavior\n   - Multi-step reasoning chains\n   - Code generation requiring accuracy verification\n\n3. **Reference to process file**: Direct users to `cove-process.md` for the detailed 4-step workflow (similar to how `analysis-process/SKILL.md` references its process files)\n\n4. **Invocation note**: Mention the skill can be invoked via `/cove` command\n\nKeep the entry point brief - detailed workflow goes in cove-process.md (task 10).",
            "status": "done",
            "testStrategy": "Verify SKILL.md contains: 1) 'When to use' or similar section header, 2) At least 4 bullet points for use cases, 3) Reference to 'cove-process.md' file, 4) Mention of '/cove' command invocation, 5) File follows concise pattern (not exceeding ~50 lines)",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:17:13.542Z"
          }
        ],
        "updatedAt": "2026-02-01T15:17:13.542Z"
      },
      {
        "id": "10",
        "title": "Implement cove-process.md verification workflow",
        "description": "Create the detailed verification workflow document that contains the complete 4-step CoVe process including verification question guidelines, output format template, and tool usage guidance.",
        "details": "Create `.github/templates/claude/skills/cove/cove-process.md` with the complete CoVe workflow.\n\n**Required sections:**\n\n1. **Workflow Checklist** (copyable format like `idea-process.md`):\n```\nCoVe Progress:\n- [ ] Step 1: Generate Initial Answer\n- [ ] Step 2: Create Verification Questions\n- [ ] Step 3: Independent Verification\n- [ ] Step 4: Reconciliation & Final Answer\n```\n\n2. **Step 1: Initial Response**\n   - Mark clearly as 'Initial Answer'\n   - Provide complete (not abbreviated) response\n   - Note areas of uncertainty\n\n3. **Step 2: Generate Verification Questions**\n   - Create 3-5 targeted questions\n   - Include table of question categories: Factual, Logical, Edge cases, Assumptions, Technical\n   - Guidelines: target critical claims, phrase for independent answering, avoid leading questions\n\n4. **Step 3: Independent Verification** (CRITICAL SECTION)\n   - **Strongly emphasize**: Answer questions WITHOUT referencing initial answer\n   - Treat each as fresh standalone question\n   - Encourage tool usage: WebSearch, context7, Read, Grep/Glob\n   - This independence prevents confirmation bias\n\n5. **Step 4: Reconciliation & Final Answer**\n   - Compare verification vs initial answer\n   - Identify discrepancies\n   - Verification answers take precedence\n   - Note corrections or confirm if no errors found\n\n6. **Output Format Template**:\n```markdown\n## Initial Answer\n[response]\n\n## Verification\n### Q1: [question]\n**A1:** [independent answer]\n[...repeat for 3-5 questions...]\n\n## Final Verified Answer\n[revised response]\n\n**Verification notes:**\n- [corrections or \"No corrections needed\"]\n```\n\n7. **Tool Usage Table**:\n| Tool | Use Case |\n|------|----------|\n| WebSearch | Current facts, recent changes |\n| context7 | Library docs, API references |\n| Read | Verify code claims |\n| Grep/Glob | Search codebase patterns |",
        "testStrategy": "1. Verify file contains copyable workflow checklist\n2. Verify all 4 steps are documented with clear instructions\n3. Verify Step 3 strongly emphasizes independent answering (search for 'without' or 'independently')\n4. Verify output format template is included and follows design spec\n5. Verify tool usage guidance table is present\n6. Verify question category table is included\n7. Compare formatting conventions with `idea-process.md`",
        "priority": "high",
        "dependencies": [
          "9"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Create workflow checklist section with copyable progress tracking",
            "description": "Create the initial section of cove-process.md containing the copyable workflow checklist following the pattern from idea-process.md. The checklist must include all 4 CoVe steps in a copy-paste friendly format.",
            "dependencies": [],
            "details": "Create the file `.github/templates/claude/skills/cove/cove-process.md` with a '### Workflow' heading and a copyable checklist block containing:\n```\nCoVe Progress:\n- [ ] Step 1: Generate Initial Answer\n- [ ] Step 2: Create Verification Questions\n- [ ] Step 3: Independent Verification\n- [ ] Step 4: Reconciliation & Final Answer\n```\nFollow the exact formatting conventions from `.github/templates/claude/skills/analysis-process/idea-process.md` which uses triple backticks for the checklist block. Include the instruction 'Copy this checklist and check off items as you complete them:' above the code block.\n<info added on 2026-02-01T15:06:49.537Z>\nI'll analyze the codebase to understand the project structure and locate the design documents mentioned in the user request.Now let me examine the specific lines mentioned in the user request (lines 119-142 of design.md for the output format template):Now let me check the Task 3 details in implementation.md:Based on my analysis of the design documents, here is the new text content that should be appended to subtask 10.1:\n\n**Design reference:** docs/wip/cove/design.md lines 119-142 contain the complete output format template that must be included in cove-process.md. This template shows the exact markdown structure with sections for Initial Answer, Verification (Q&A pairs), Final Verified Answer, and Verification notes.\n\n**Implementation reference:** docs/wip/cove/implementation.md Task 3 (lines 50-94) provides the complete content section specifications for cove-process.md including all 7 required sections: (1) Workflow Checklist with format `- [ ] Step N: Description`, (2) Step 1: Initial Response instructions, (3) Step 2: Generate Verification Questions with categories table and guidelines, (4) Step 3: Independent Verification with critical independence requirements and tool usage guidance, (5) Step 4: Reconciliation & Final Answer with discrepancy handling, (6) Output Format Template (the exact template from design.md:119-142), and (7) Tool Usage During Verification table.\n\n**Critical implementation detail from implementation.md:193-195:** Step 3 must strongly emphasize answering verification questions without referencing the initial answer. This independence prevents confirmation bias and is the key mechanism for catching errors. Use explicit language like 'Do NOT reference the initial answer' and 'Treat each question as coming from a new user'.\n\n**File location:** Create `.github/templates/claude/skills/cove/cove-process.md` (note the `.github/templates/` prefix for template files, as established by the project's template-sync infrastructure).\n</info added on 2026-02-01T15:06:49.537Z>",
            "status": "done",
            "testStrategy": "Verify file exists at correct path. Verify checklist contains exactly 4 steps with matching step names from design spec. Verify format uses code block for copyability.",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:20:06.664Z"
          },
          {
            "id": 2,
            "title": "Document Steps 1-2: Initial Response and Verification Questions",
            "description": "Add detailed documentation for Step 1 (Initial Response) and Step 2 (Generate Verification Questions) including the question categories table and guidelines for effective verification questions.",
            "dependencies": [
              1
            ],
            "details": "Add to cove-process.md two complete step sections:\n\n**Step 1: Initial Response**\n- Requirement to mark clearly as 'Initial Answer'\n- Instruction to provide complete (not abbreviated) response\n- Note areas of uncertainty\n\n**Step 2: Generate Verification Questions**\n- Instructions to create 3-5 targeted questions\n- Include markdown table with categories: Factual, Logical, Edge cases, Assumptions, Technical (copy format from design.md lines 73-79)\n- Guidelines: target critical claims, phrase for independent answering, avoid leading questions, include at least one assumption-challenging question\n\nUse imperative mood throughout ('Generate...', 'Create...') consistent with existing skills.",
            "status": "done",
            "testStrategy": "Verify Step 1 section exists with 'Initial Answer' marking requirement. Verify Step 2 contains 5-category table. Verify guidelines mention 'independently' or 'independent'. Verify 3-5 questions requirement is stated.",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:20:06.667Z"
          },
          {
            "id": 3,
            "title": "Document Step 3: Independent Verification with strong independence emphasis",
            "description": "Add the critical Step 3 section emphasizing independent verification without referencing the initial answer. This is the most important section for preventing confirmation bias.",
            "dependencies": [
              1
            ],
            "details": "Add Step 3: Independent Verification section with strong emphasis on independence:\n\n1. **Bold/emphasized statement**: Answer each question WITHOUT referencing the initial answer\n2. Instruction to treat each question as a fresh standalone question from a new user\n3. Tool usage encouragement section with table:\n   | Tool | Use Case |\n   |------|----------|\n   | WebSearch | Current facts, recent changes |\n   | context7 | Library docs, API references |\n   | Read | Verify code claims |\n   | Grep/Glob | Search codebase patterns |\n4. Explicit warning that this independence prevents confirmation bias\n5. Use phrases like 'independently', 'without', 'do NOT reference' multiple times to reinforce the critical requirement\n\nThis section must be the most emphatic in the document per the PRD requirement.",
            "status": "done",
            "testStrategy": "Search document for 'without' or 'independently' - should appear multiple times in Step 3. Verify tool usage table exists with all 4 tools. Verify confirmation bias is mentioned. Verify 'do NOT reference' or similar strong language is present.",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:20:06.675Z"
          },
          {
            "id": 4,
            "title": "Document Step 4 and output format template with verification notes",
            "description": "Add Step 4 (Reconciliation & Final Answer) documentation and the complete output format template showing the expected structure for CoVe responses.",
            "dependencies": [
              2,
              3
            ],
            "details": "Add two sections to complete cove-process.md:\n\n**Step 4: Reconciliation & Final Answer**\n- Instructions for comparing verification answers vs initial answer\n- Process for identifying discrepancies\n- Rule: verification answers take precedence when conflicts arise\n- Handling for when no errors found (note corrections or confirm initial answer)\n\n**Output Format Template** section with complete markdown template:\n```markdown\n## Initial Answer\n[response]\n\n## Verification\n### Q1: [question]\n**A1:** [independent answer]\n[...repeat for 3-5 questions...]\n\n## Final Verified Answer\n[revised response]\n\n**Verification notes:**\n- [corrections or \"No corrections needed\"]\n```\n\nEnsure template exactly matches design.md format (lines 119-142) and PRD requirements.",
            "status": "done",
            "testStrategy": "Verify Step 4 mentions 'verification answers take precedence' or 'precedence'. Verify output format template exists with all 3 sections (Initial Answer, Verification, Final Verified Answer). Verify verification notes section is included in template. Verify Q1/A1 pattern shown.",
            "parentId": "undefined",
            "updatedAt": "2026-02-01T15:20:06.677Z"
          }
        ],
        "updatedAt": "2026-02-01T15:20:06.677Z"
      },
      {
        "id": "11",
        "title": "Create /cove slash command",
        "description": "Create the slash command at `.claude/commands/cove/cove.md` that invokes the CoVe skill, handling both question arguments and verification of previous responses.",
        "details": "Create command directory and file: `.github/templates/claude/commands/cove/cove.md`\n\n**Content structure:**\n\n1. **Brief description** (1-2 lines):\n   - Apply Chain-of-Verification to improve response accuracy\n\n2. **Arguments handling** (similar to `show-task.md` pattern):\n```\nArguments: $ARGUMENTS\n```\n\n3. **Invocation logic:**\n   - If `$ARGUMENTS` provided: Apply CoVe to the given question\n   - If `$ARGUMENTS` empty: Apply CoVe to verify the previous response in conversation\n\n4. **Skill invocation instruction:**\n   - Reference and invoke the `cove` skill\n   - Follow the process in `cove-process.md`\n\n5. **Brief usage examples** (optional, 2-3 lines):\n   - `/cove What is the time complexity of Python's sorted()?`\n   - `/cove` (after receiving a response to verify)\n\n**Keep the command file concise** - it's an entry point that delegates to the skill, not a full workflow document.",
        "testStrategy": "1. Verify directory `.github/templates/claude/commands/cove/` exists\n2. Verify `cove.md` handles `$ARGUMENTS` variable\n3. Verify command describes both with-arguments and no-arguments behavior\n4. Verify command references the cove skill\n5. Check formatting follows existing command patterns (compare with tm commands)",
        "priority": "high",
        "dependencies": [
          "9"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create cove command directory structure",
            "description": "Create the directory `.github/templates/claude/commands/cove/` to house the CoVe slash command file.",
            "dependencies": [],
            "details": "Create the directory using `mkdir -p .github/templates/claude/commands/cove/`. This follows the existing pattern where commands are organized in subdirectories under `.github/templates/claude/commands/` (like `tm/show/`, `tm/next/`, etc.). The directory must exist before the cove.md file can be created.\n<info added on 2026-02-01T15:07:12.715Z>\nI'll analyze the codebase structure to understand the slash command patterns and then provide the specific implementation details for subtask 11.1.Based on my analysis of the existing command structure in `.github/templates/claude/commands/tm/` and the design/implementation documents, here is the new text content to append to subtask 11.1:\n\n---\n\nThe command directory follows the template-based structure where files in `.github/templates/` are synced to `.claude/` during template operations. Per the implementation plan (docs/wip/cove/implementation.md Task 4), the slash command will be located at `.github/templates/claude/commands/cove/cove.md` and will handle arguments using the `$ARGUMENTS` variable pattern seen in commands like `.github/templates/claude/commands/tm/show/show-task.md`. The design document (docs/wip/cove/design.md lines 145-159) specifies two invocation modes: with arguments to verify a specific question, and without arguments to verify the previous response in the conversation.\n</info added on 2026-02-01T15:07:12.715Z>",
            "status": "pending",
            "testStrategy": "Verify directory `.github/templates/claude/commands/cove/` exists using `ls -la .github/templates/claude/commands/cove/` or checking with file explorer.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement cove.md command file with argument handling",
            "description": "Create the `cove.md` command file with proper description, $ARGUMENTS handling for both question and verify-previous-response modes, and skill invocation reference.",
            "dependencies": [
              1
            ],
            "details": "Create `.github/templates/claude/commands/cove/cove.md` following the patterns from existing commands like `show-task.md`. The file must include: (1) Brief 1-2 line description about applying CoVe for improved accuracy; (2) Arguments line: `Arguments: $ARGUMENTS`; (3) Conditional logic section explaining behavior when $ARGUMENTS is provided (apply CoVe to the question) vs when empty (verify previous response in conversation); (4) Instruction to invoke the `cove` skill and follow the process in `cove-process.md`; (5) Optional brief usage examples showing `/cove What is the time complexity of...` and `/cove` for verification.",
            "status": "pending",
            "testStrategy": "Verify cove.md exists and contains: $ARGUMENTS variable, description of with-arguments and no-arguments behavior, reference to cove skill/cove-process.md, formatting consistent with show-task.md pattern.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Verify command structure and integration with skill",
            "description": "Validate the command file follows existing patterns, properly references the cove skill, and handles both invocation modes correctly.",
            "dependencies": [
              2
            ],
            "details": "Perform validation checks: (1) Compare cove.md structure against existing commands like `show-task.md` and `next-task.md` to ensure consistent formatting; (2) Verify the skill reference points to the correct skill name `cove` which will be defined in SKILL.md; (3) Check that argument handling logic clearly distinguishes between providing a question and verifying previous response; (4) Ensure the command is concise (entry point only) and delegates workflow details to the skill; (5) Verify file uses imperative mood and matches markdown conventions from other commands.",
            "status": "pending",
            "testStrategy": "Perform diff/comparison with show-task.md for structural consistency. Grep for 'cove' skill reference. Manual review that both invocation modes are clearly documented. Verify file length is appropriately concise (roughly 20-40 lines, not a full workflow document).",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "12",
        "title": "Add natural language invocation triggers to skill",
        "description": "Update the SKILL.md to include natural language trigger phrases that Claude should recognize as requests to use the CoVe skill without explicit /cove invocation.",
        "details": "Enhance `.github/templates/claude/skills/cove/SKILL.md` to include natural language recognition.\n\n**Add section for trigger phrases:**\n\nRecognize these phrases as invocation requests:\n- \"verify this using chain of verification\"\n- \"use CoVe to answer\"\n- \"fact-check your response\"\n- \"double-check this with verification\"\n- \"use self-verification for this\"\n\n**Implementation approach:**\nAdd a section titled 'Natural Language Invocation' that lists phrases Claude should recognize. This enables the skill to be invoked without memorizing the exact `/cove` command.\n\n**Also add 'When to Use' guidance:**\n- Questions requiring precision (\"exactly\", \"precisely\", \"specific\")\n- Multi-step reasoning chains (3+ logical steps)\n- Technical claims about APIs or version-specific behavior\n- Historical facts, statistics, or quantitative data\n- Security-critical code analysis\n- When initial response contains hedging (\"I think\", \"probably\")\n\n**Note:** This is guidance only - auto-trigger is NOT implemented by default (per PRD non-goal). Users who want auto-trigger can reference this in their project CLAUDE.md.",
        "testStrategy": "1. Verify SKILL.md contains 'Natural Language Invocation' section\n2. Verify at least 3 trigger phrases are documented\n3. Verify 'When to Use' guidance is included\n4. Verify the skill does NOT implement auto-trigger by default\n5. Verify guidance mentions users can add auto-trigger to their CLAUDE.md if desired",
        "priority": "medium",
        "dependencies": [
          "9",
          "10"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Add Natural Language Invocation section with trigger phrases",
            "description": "Add a new section titled 'Natural Language Invocation' to SKILL.md that lists the phrases Claude should recognize as requests to invoke the CoVe skill without explicit /cove command.",
            "dependencies": [],
            "details": "Edit `.github/templates/claude/skills/cove/SKILL.md` to add a new section after the existing content. The section should include:\n\n**Section Header:** '## Natural Language Invocation'\n\n**Introductory text:** Brief explanation that Claude should recognize these phrases as requests to invoke the CoVe skill.\n\n**Trigger phrases list (minimum 5):**\n- \"verify this using chain of verification\"\n- \"use CoVe to answer\"\n- \"fact-check your response\"\n- \"double-check this with verification\"\n- \"use self-verification for this\"\n\n**Important notes to include:**\n- This is guidance for manual recognition only\n- Auto-trigger is NOT implemented by default (per PRD non-goal)\n- Users who want auto-trigger behavior can reference this section in their project CLAUDE.md to enable automatic invocation\n\nFollow the markdown formatting conventions from existing skills (imperative mood, concise bullet points).",
            "status": "pending",
            "testStrategy": "1. Verify SKILL.md contains 'Natural Language Invocation' section header\n2. Verify at least 5 trigger phrases are documented in a bullet list\n3. Grep for 'verify this using chain of verification' and 'use CoVe' phrases\n4. Verify explicit note that auto-trigger is NOT default behavior\n5. Verify mention of users adding to CLAUDE.md for auto-trigger",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Add When to Use guidance section with auto-trigger indicators",
            "description": "Add a 'When to Use' guidance section that documents the scenarios and heuristics where CoVe is most beneficial, providing users with criteria they can optionally use for auto-trigger configuration.",
            "dependencies": [
              1
            ],
            "details": "Add a new section to SKILL.md titled '## When to Use' or integrate with existing when-to-use content. Document the specific scenarios where CoVe provides the most value:\n\n**Precision indicators:**\n- Questions containing precision language (\"exactly\", \"precisely\", \"specific\")\n\n**Complexity indicators:**\n- Multi-step reasoning chains (3+ logical dependencies)\n- Technical claims about APIs, libraries, or version-specific behavior\n\n**Fact-checking scenarios:**\n- Historical facts, statistics, or quantitative data\n- Security-critical code paths or analysis\n\n**Self-correction triggers:**\n- When initial response contains hedging language (\"I think\", \"probably\", \"might be\")\n\n**Implementation notes:**\n- These are guidelines for when CoVe adds value, not automatic triggers\n- Reference design.md lines 170-177 for auto-trigger indicator specification\n- Users can copy these heuristics to their CLAUDE.md to enable auto-invocation if desired\n\nThis section serves dual purposes: helping users decide when to manually invoke /cove, and providing copy-paste heuristics for those who want to configure auto-trigger in their project.",
            "status": "pending",
            "testStrategy": "1. Verify 'When to Use' section exists with guidance content\n2. Verify at least 6 indicator types are documented (precision, multi-step, technical claims, historical facts, security-critical, hedging language)\n3. Verify explicit mention that users can add auto-trigger to CLAUDE.md\n4. Verify section does NOT implement auto-trigger itself\n5. Verify formatting is consistent with existing skill documentation patterns",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": "13",
        "title": "Validate CoVe skill integration and output format",
        "description": "Perform integration testing to verify the skill appears in Claude's skill list, the /cove command invokes correctly, all four verification steps appear in output, and the skill follows project conventions.",
        "details": "Comprehensive validation of the complete CoVe implementation.\n\n**Validation checklist:**\n\n1. **File structure verification:**\n   - `.github/templates/claude/skills/cove/SKILL.md` exists with valid frontmatter\n   - `.github/templates/claude/skills/cove/cove-process.md` exists with complete workflow\n   - `.github/templates/claude/commands/cove/cove.md` exists with argument handling\n\n2. **Content validation:**\n   - SKILL.md name field is exactly 'cove'\n   - SKILL.md description mentions verification/accuracy\n   - cove-process.md contains all 4 steps\n   - cove-process.md has output format template\n   - cove.md handles both with/without arguments\n\n3. **Convention compliance:**\n   - YAML frontmatter format matches other skills\n   - Markdown formatting is consistent\n   - Imperative mood used in instructions\n   - No code examples in skill files (prompting technique only)\n   - No modifications to CLAUDE.md or settings.json\n\n4. **Test scenarios to document:**\n   - `/cove What is the default port for PostgreSQL?`\n   - Previous response verification (no args)\n   - Natural language: \"Use chain of verification to answer...\"\n   - Code verification scenario\n\n5. **Expected output structure:**\n   - Initial Answer section present\n   - Verification section with 3-5 Q&A pairs\n   - Final Verified Answer section present\n   - Verification notes listing corrections or confirmation\n\n**Create test documentation** in `docs/wip/cove/` noting the test scenarios and expected behaviors for manual verification.",
        "testStrategy": "1. Run file existence checks for all 3 created files\n2. Parse YAML frontmatter in SKILL.md and verify name='cove'\n3. Search cove-process.md for key terms: 'Initial Answer', 'Verification', 'Independent', 'Final'\n4. Search cove.md for '$ARGUMENTS' handling\n5. Verify no changes made to CLAUDE.md or settings.json (per PRD non-goals)\n6. Document test scenarios for future manual validation\n7. Verify output format template in cove-process.md matches design spec exactly",
        "priority": "medium",
        "dependencies": [
          "9",
          "10",
          "11",
          "12"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Verify file structure and content compliance",
            "description": "Validate that all CoVe skill files exist in the correct locations with proper content structure following project conventions.",
            "dependencies": [],
            "details": "Perform file existence checks and content validation:\n\n1. **Directory structure verification:**\n   - Verify `.github/templates/claude/skills/cove/` directory exists\n   - Verify `.github/templates/claude/commands/cove/` directory exists\n\n2. **File existence checks:**\n   - `.github/templates/claude/skills/cove/SKILL.md` exists\n   - `.github/templates/claude/skills/cove/cove-process.md` exists\n   - `.github/templates/claude/commands/cove/cove.md` exists\n\n3. **SKILL.md content validation:**\n   - Parse YAML frontmatter and verify `name` field equals exactly `cove`\n   - Verify `description` field mentions verification, accuracy, or fact-checking\n   - Verify file contains reference to `cove-process.md`\n   - Compare frontmatter format against existing skills (e.g., `.github/templates/claude/skills/testing-process/SKILL.md`)\n\n4. **cove-process.md content validation:**\n   - Search for all 4 CoVe steps: Initial Answer, Generate Verification Questions, Independent Verification, Final Verified Answer\n   - Verify output format template exists with sections: Initial Answer, Verification (Q&A pairs), Final Verified Answer, Verification notes\n   - Verify tool usage guidance is present (WebSearch, context7, Read, Grep)\n\n5. **cove.md command validation:**\n   - Verify `$ARGUMENTS` variable handling exists\n   - Verify both with-arguments and no-arguments behavior documented\n   - Verify skill invocation reference is present\n\n6. **Convention compliance:**\n   - Verify no modifications made to CLAUDE.md or settings.json\n   - Compare markdown formatting against existing skills for consistency\n   - Verify imperative mood used in instructions",
            "status": "pending",
            "testStrategy": "Use Glob to verify directories exist, Read to examine file contents, Grep to search for required terms (YAML fields, step names, output format sections). Compare structure against existing skills like testing-process and analysis-process for convention compliance.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Create test scenarios documentation",
            "description": "Document comprehensive test scenarios with expected behaviors for manual verification of the CoVe skill functionality.",
            "dependencies": [
              1
            ],
            "details": "Create test documentation in `docs/wip/cove/test-scenarios.md` covering:\n\n1. **Slash command with question test:**\n   - Input: `/cove What is the default port for PostgreSQL?`\n   - Expected: Full 4-step CoVe workflow\n   - Verify: Initial Answer identifies port 5432, verification questions challenge this, independent answers confirm, final answer states verified port\n\n2. **Previous response verification test:**\n   - Step 1: Ask a factual question (e.g., \"What is TCP?\")\n   - Step 2: Invoke `/cove` without arguments\n   - Expected: CoVe applies to the previous response\n   - Verify: All 4 steps present, verification questions relevant to previous response topic\n\n3. **Natural language invocation test:**\n   - Input: \"Use chain of verification to answer: What is the memory limit for AWS Lambda?\"\n   - Expected: Skill recognized and invoked\n   - Verify: Same 4-step structure appears\n\n4. **Code verification scenario test:**\n   - Input: `/cove Is binary search O(log n) time complexity?`\n   - Expected: Verification questions about algorithm analysis\n   - Verify: Questions cover edge cases, assumptions, and technical correctness\n\n5. **Output format checklist for each test:**\n   - [ ] Initial Answer section clearly marked\n   - [ ] Verification section has 3-5 Q&A pairs\n   - [ ] Q&A pairs use independent reasoning (no self-reference)\n   - [ ] Final Verified Answer section present\n   - [ ] Verification notes list corrections OR confirm no corrections needed\n\n6. **Edge case documentation:**\n   - Ambiguous questions\n   - Questions where initial answer is already correct\n   - Questions where verification finds errors",
            "status": "pending",
            "testStrategy": "Review the created test-scenarios.md file to ensure all 4 test scenarios are documented with clear inputs, expected outputs, and verification checklists. Verify the document follows markdown formatting conventions.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Perform end-to-end validation and finalize documentation",
            "description": "Execute manual verification of all test scenarios in Claude Code and document results with any issues found.",
            "dependencies": [
              1,
              2
            ],
            "details": "Perform end-to-end validation and create final validation report:\n\n1. **Pre-validation setup:**\n   - Ensure template-sync has been run to copy CoVe files to `.claude/` directory\n   - Verify `/mcp` shows all servers connected\n   - Clear Claude Code context with `/clear`\n\n2. **Execute test scenarios from test-scenarios.md:**\n   - Run each of the 4 documented test scenarios\n   - Record actual output for each test\n   - Note any deviations from expected behavior\n\n3. **Skill integration verification:**\n   - Verify skill appears when user references CoVe or chain of verification\n   - Verify `/cove` command is recognized\n   - Verify natural language triggers skill invocation\n\n4. **Output format validation for each test:**\n   - Verify Initial Answer section is present and complete\n   - Verify 3-5 verification questions are generated\n   - Verify independent answers don't reference initial answer\n   - Verify Final Verified Answer synthesizes verification findings\n   - Verify Verification notes section present\n\n5. **Create validation-report.md in `docs/wip/cove/`:**\n   - Summary: Pass/Fail for each test scenario\n   - Detailed results for each test with actual output snippets\n   - Issues found (if any) with severity and suggested fixes\n   - Convention compliance checklist results\n   - Recommendations for improvements (if any)\n\n6. **Final checklist verification:**\n   - [ ] All 3 CoVe files exist and have correct content\n   - [ ] SKILL.md name field is exactly 'cove'\n   - [ ] cove-process.md contains all 4 steps\n   - [ ] cove.md handles arguments correctly\n   - [ ] No changes to CLAUDE.md or settings.json\n   - [ ] Output format matches design specification",
            "status": "pending",
            "testStrategy": "Execute all test scenarios manually in Claude Code, document results in validation-report.md. Create a pass/fail summary with evidence (output snippets). Flag any issues with clear descriptions and reproduction steps.",
            "parentId": "undefined"
          }
        ]
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-01T15:20:06.677Z",
      "taskCount": 5,
      "completedCount": 2,
      "tags": [
        "master"
      ]
    }
  }
}